{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c255f8e7",
   "metadata": {},
   "source": [
    "# ğŸ§  Study Buddy â€” Build Your Own RAG Chatbot with Gemini\n",
    "Upload any PDF or text file (e.g., course notes, a Wikipedia export, or an article).\n",
    "\n",
    "Ask questions like:\n",
    "- â€œSummarize Chapter 2â€\n",
    "- â€œWhat is reinforcement learning?â€\n",
    "- â€œWhatâ€™s the main takeaway from this section?â€\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1359b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§© Step 1: Install dependencies\n",
    "!pip install -q google-generativeai PyPDF2 faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ff5e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§  Step 2: Import libraries\n",
    "import google.generativeai as genai\n",
    "from getpass import getpass\n",
    "import PyPDF2\n",
    "import faiss\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5777121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš™ï¸ Step 3: Configure Gemini API\n",
    "GEMINI_API_KEY = getpass(\"ğŸ”‘ Enter your Gemini API key: \")\n",
    "genai.configure(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¾ Step 4: Upload your study material\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "file_name = list(uploaded.keys())[0]\n",
    "text = \"\"\n",
    "\n",
    "if file_name.endswith(\".pdf\"):\n",
    "    reader = PyPDF2.PdfReader(file_name)\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() or \"\"\n",
    "else:\n",
    "    text = uploaded[file_name].decode(\"utf-8\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(text)} characters from {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9256317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸª„ Step 5: Split text into chunks\n",
    "def split_text(text, chunk_size=1000, overlap=200):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = split_text(text)\n",
    "print(f\"ğŸ“š Split into {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b395fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§© Step 6: Create embeddings and index\n",
    "embed_model = \"models/embedding-001\"\n",
    "embeddings = []\n",
    "\n",
    "for chunk in chunks:\n",
    "    result = genai.embed_content(model=embed_model, content=chunk)\n",
    "    embeddings.append(result[\"embedding\"])\n",
    "\n",
    "embeddings = np.array(embeddings, dtype=\"float32\")\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "print(\"âœ… Vector index built!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ’¬ Step 7: Define RAG query function\n",
    "def retrieve(query, k=3):\n",
    "    q_embed = genai.embed_content(model=embed_model, content=query)[\"embedding\"]\n",
    "    _, idx = index.search(np.array([q_embed], dtype=\"float32\"), k)\n",
    "    return [chunks[i] for i in idx[0]]\n",
    "\n",
    "def ask_study_buddy(query):\n",
    "    docs = retrieve(query)\n",
    "    context = \"\\n\\n\".join(docs)\n",
    "    prompt = f\"You are Study Buddy, a helpful assistant for learning.\\nUse the context below to answer the question concisely and clearly.\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "# ğŸ§ª Step 8: Try asking a question\n",
    "question = \"Summarize Chapter 2\"\n",
    "print(f\"ğŸ¤” Q: {question}\\n\")\n",
    "print(\"ğŸ’¡ A:\", ask_study_buddy(question))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
